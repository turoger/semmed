{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pykeen\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create a TriplesFactory Object from tab separated file\n",
    "* Get files loaded as np arrays\n",
    "* Get unique entities and relations\n",
    "* Assign counts to the unique entities and relations\n",
    "* Shuffle the values to get random assignment of entities and relation dict to ids\n",
    "* Create your TriplesFactory Object\n",
    "\n",
    "## Import your triples with pykeen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numpy factory for dataset\n",
    "train = pykeen.triples.utils.load_triples(\n",
    "    \"./semmed/data/time_networks-6_metanode/1987/hpo_train_notime.txt\",\n",
    ")\n",
    "test = pykeen.triples.utils.load_triples(\n",
    "    \"./semmed/data/time_networks-6_metanode/1987/hpo_test_notime.txt\",\n",
    ")\n",
    "valid = pykeen.triples.utils.load_triples(\n",
    "    \"./semmed/data/time_networks-6_metanode/1987/hpo_valid_notime.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dimensions\n",
    "* can create your inference group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check what the imported files look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = np.concatenate([test, valid])\n",
    "assert (\n",
    "    test.shape[0] + valid.shape[0] == inference.shape[0]\n",
    "), \"Assumption that test and valid are added together in the same dimension is incorrect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create entity2id and relation2id mapping\n",
    "* get train file from import\n",
    "* combine head and tail to get entities\n",
    "* get unique relations\n",
    "* assign values and shuffle for each dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(\n",
    "    \"./semmed/data/time_networks-6_metanode/1987/hpo_train_notime.txt\",\n",
    "    separator=\"\\t\",\n",
    "    has_header=False,\n",
    ").rename({\"column_1\": \"head\", \"column_2\": \"relation\", \"column_3\": \"tail\"})\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get unique entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique entity series\n",
    "entities = (\n",
    "    train_df.select(\"head\")\n",
    "    .vstack(train_df.select(\"tail\").rename({\"tail\": \"head\"}))\n",
    "    .unique(\"head\")\n",
    ")\n",
    "entities.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get unique relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique relation series\n",
    "relations = train_df.select(\"relation\").unique(\"relation\")\n",
    "\n",
    "relations.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a np array of all ents and relations, then shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a np array of the entities and relations\n",
    "# then shuffle the arrays, in-place\n",
    "rel_arr = np.arange(relations.shape[0])\n",
    "ent_arr = np.arange(entities.shape[0])\n",
    "np.random.shuffle(rel_arr)  # shuffle the array, happens in-place\n",
    "np.random.shuffle(ent_arr)  # shuffle the array, happens in-place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign shuffled ids to the nodes\n",
    "* create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the new, shuffled id to the nodes\n",
    "e2id = entities.with_columns(new_id=pl.Series(ent_arr)).select([\"head\", \"new_id\"])\n",
    "# create node mappings\n",
    "e2id_dict = dict(zip(e2id[\"head\"], e2id[\"new_id\"]))\n",
    "\n",
    "# assign the new, shuffled id to the edges\n",
    "r2id = relations.with_columns(new_id=pl.Series(rel_arr)).select([\"relation\", \"new_id\"])\n",
    "r2id_dict = dict(zip(r2id[\"relation\"], r2id[\"new_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Triples Factory Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_factory = pykeen.triples.TriplesFactory.from_labeled_triples(\n",
    "    triples=train,\n",
    "    create_inverse_triples=True,\n",
    "    entity_to_id=e2id_dict,\n",
    "    relation_to_id=r2id_dict,\n",
    ")\n",
    "\n",
    "training_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_factory = pykeen.triples.TriplesFactory.from_labeled_triples(\n",
    "    triples=inference,\n",
    "    create_inverse_triples=True,  # must be set to true for nodepiece\n",
    "    entity_to_id=e2id_dict,\n",
    "    relation_to_id=r2id_dict,\n",
    ")\n",
    "\n",
    "inference_factory"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
