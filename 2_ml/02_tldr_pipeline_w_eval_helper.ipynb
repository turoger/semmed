{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval helper Overview\n",
    "* I wrote two helper scripts to help run the time-leveraged pipeline: eval_helper and analysis_helper\n",
    "* This notebook focuses on how to use eval_helper\n",
    "* eval_helper finds the years in our modified SemMedDB dataset (TLDR) with the most approved drug-disease indications and can train a knowledge graph embedding model on those selected year\n",
    "* two main steps:\n",
    "    * pick the best years to train models on\n",
    "    * train models on the specified years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"../tools\")\n",
    "import eval_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the eval_helper class\n",
    "* the docstring is pretty self explanatory on how to use the class\n",
    "* eval_helper takes several variables:\n",
    "    * `models_to_run` - is the number of years you want to train models on\n",
    "    * `strategy` is the approach to identify the best years to train models on. two options - max_valid and max_test_valid\n",
    "    * `train_models` - whether or not you want to train a model. If True it will run the training loop by calling pykeen on the dataset years chosen above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the max_test_valid strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = eval_helper.TimeDrugRepo(\n",
    "    data_dir=\"/home/rogertu/.data/pykeen/datasets/timeresolvedkg/data/time_networks-6_metanode\",\n",
    "    strategy=\"max_test_valid\",\n",
    "    build_dataset_kwargs={\"split_ttv\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommended years to train models on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1994, 2020, 1979, 2019, 2017]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.recommended_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>train_indications</th><th>test_indications</th><th>valid_indications</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1979</td><td>1393</td><td>348</td><td>1593</td></tr><tr><td>1994</td><td>2412</td><td>602</td><td>1564</td></tr><tr><td>2017</td><td>3723</td><td>930</td><td>444</td></tr><tr><td>2019</td><td>3989</td><td>997</td><td>287</td></tr><tr><td>2020</td><td>4204</td><td>1050</td><td>218</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────┬───────────────────┬──────────────────┬───────────────────┐\n",
       "│ year ┆ train_indications ┆ test_indications ┆ valid_indications │\n",
       "│ ---  ┆ ---               ┆ ---              ┆ ---               │\n",
       "│ i64  ┆ i64               ┆ i64              ┆ i64               │\n",
       "╞══════╪═══════════════════╪══════════════════╪═══════════════════╡\n",
       "│ 1979 ┆ 1393              ┆ 348              ┆ 1593              │\n",
       "│ 1994 ┆ 2412              ┆ 602              ┆ 1564              │\n",
       "│ 2017 ┆ 3723              ┆ 930              ┆ 444               │\n",
       "│ 2019 ┆ 3989              ┆ 997              ┆ 287               │\n",
       "│ 2020 ┆ 4204              ┆ 1050             ┆ 218               │\n",
       "└──────┴───────────────────┴──────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.recommended_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the max_valid strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = eval_helper.TimeDrugRepo(\n",
    "    data_dir=\"/home/rogertu/.data/pykeen/datasets/timeresolvedkg/data/time_networks-6_metanode\",\n",
    "    strategy=\"max_valid\",\n",
    "    build_dataset_kwargs={\"split_ttv\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended years to train models on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1994, 1979, 1964, 2007, 1952]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.recommended_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>train_indications</th><th>test_indications</th><th>valid_indications</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1952</td><td>76</td><td>18</td><td>498</td></tr><tr><td>1964</td><td>422</td><td>105</td><td>920</td></tr><tr><td>1979</td><td>1393</td><td>348</td><td>1593</td></tr><tr><td>1994</td><td>2412</td><td>602</td><td>1564</td></tr><tr><td>2007</td><td>3084</td><td>770</td><td>1071</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────┬───────────────────┬──────────────────┬───────────────────┐\n",
       "│ year ┆ train_indications ┆ test_indications ┆ valid_indications │\n",
       "│ ---  ┆ ---               ┆ ---              ┆ ---               │\n",
       "│ i64  ┆ i64               ┆ i64              ┆ i64               │\n",
       "╞══════╪═══════════════════╪══════════════════╪═══════════════════╡\n",
       "│ 1952 ┆ 76                ┆ 18               ┆ 498               │\n",
       "│ 1964 ┆ 422               ┆ 105              ┆ 920               │\n",
       "│ 1979 ┆ 1393              ┆ 348              ┆ 1593              │\n",
       "│ 1994 ┆ 2412              ┆ 602              ┆ 1564              │\n",
       "│ 2007 ┆ 3084              ┆ 770              ┆ 1071              │\n",
       "└──────┴───────────────────┴──────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.recommended_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models\n",
    "* its as simple as initializing a model, and specifying the model during initialization\n",
    "* here we'll use TransE as an example on how to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage location for the postgres hpo database\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    url=\"postgresql+psycopg2://rogertu:admin@localhost/optuna_test\"\n",
    ")\n",
    "\n",
    "# get the best parameters from the hpo study\n",
    "transe = optuna.study.load_study(storage=storage, study_name=\"transe_hpo_time3\")\n",
    "transe_params = transe.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model kwargs and parameters for training\n",
    "model_kwargs = dict(\n",
    "    # Model\n",
    "    model=\"TransE\",\n",
    "    model_kwargs=dict(scoring_fct_norm=2, embedding_dim=100),\n",
    "    # Loss\n",
    "    loss=\"InfoNCELoss\",\n",
    "    loss_kwargs=dict(\n",
    "        margin=transe_params[\"loss.margin\"],\n",
    "        log_adversarial_temperature=transe_params[\"loss.log_adversarial_temperature\"],\n",
    "    ),\n",
    "    # Regularization\n",
    "    regularizer=\"LpRegularizer\",\n",
    "    regularizer_kwargs=dict(weight=transe_params[\"regularizer.weight\"]),\n",
    "    # Training\n",
    "    training_kwargs=dict(\n",
    "        num_epochs=10,\n",
    "        batch_size=144,\n",
    "        checkpoint_frequency=0,\n",
    "        checkpoint_name=\"TransE.pt\",\n",
    "    ),\n",
    "    # Negative Sampler\n",
    "    negative_sampler=\"basic\",\n",
    "    negative_sampler_kwargs=dict(\n",
    "        num_negs_per_pos=transe_params[\n",
    "            \"negative_sampler.num_negs_per_pos\"\n",
    "        ],  # corruption_scheme=(\"h\",\"r\",\"t\",),  # defines which part of the triple to corrupt\n",
    "        filtered=True,  # Uses a default 'Bloom' filter to minimize false negatives\n",
    "    ),\n",
    "    # optimizer\n",
    "    optimizer=\"Adam\",\n",
    "    optimizer_kwargs=dict(lr=transe_params[\"optimizer.lr\"]),\n",
    "    # lr scheduler\n",
    "    lr_scheduler=\"ExponentialLR\",\n",
    "    lr_scheduler_kwargs=dict(gamma=transe_params[\"lr_scheduler.gamma\"]),\n",
    "    # Tracking\n",
    "    result_tracker=\"wandb\",\n",
    "    result_tracker_kwargs=dict(project=\"KGE-on-time-results\", group=\"transe\"),\n",
    "    # Misc\n",
    "    device=\"cuda:0\",  # use gpu position 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "x = eval_helper.TimeDrugRepo(\n",
    "    data_dir=\"/home/rogertu/.data/pykeen/datasets/timeresolvedkg/data/time_networks-6_metanode\",\n",
    "    strategy=\"max_test_valid\",\n",
    "    build_dataset_kwargs={\"split_ttv\": True},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
